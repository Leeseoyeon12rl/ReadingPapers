{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMaEQc38iy9dd4HawfBXWYQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rUnr8z9tHKwU"},"outputs":[],"source":["# This code is to implement deep fingerprinting model for website fingerprinting attacks\n","# Deep Fingerprinting: Undermining Website Fingerprinting Defenses with Deep Learning\n","\n","from keras import backend as K\n","from utility import LoadDataWalkieTalkieCW\n","from Model_WalkieTalkie import DFNet\n","import random\n","from keras.utils import np_utils\n","from keras.optimizers import Adamax\n","import numpy as np\n","import os\n","\n","random.seed(0)\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","\n","# Use only CPU\n","\n","description = \"Training and evaluating DF model for closed-world scenario on Walkie-Talkie dataset\"\n","print(description)"]},{"cell_type":"code","source":["# Training the DF model\n","NB_EPOCH = 30\n","print(\"Number of Epoch: \", NB_EPOCH)\n","BATCH_SIZE = 128\n","VERBOSE = 2\n","LENGTH = 5000\n","OPTIMIZER = Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n","\n","NB_CLASSES = 100\n","INPUT_SHAPE = (LENGTH, 1)\n","\n","# Data: shuffled and split between train and test sets\n","print(\"Loading and preparing data for training, and evaluating the model\")\n","X_train, y_train, X_valid, y_valid, X_test, y_test = LoadDataWalkieTalkieCW()\n","# Please refer to the dataset format in readme\n","K.set_image_dim_ordering(\"tf\") # tf is tensorflow\n","\n","# Convert data as float32 type\n","X_train = X_train.astype('float32')\n","X_valid = X_valid.astype('float32')\n","X_test = X_test.astype('float32')\n","y_train = y_train.astype('float32')\n","y_valid = y_valid.astype('float32')\n","y_test = y_test.astype('float32')\n","\n","# we need a [Length x 1] x n shape as input to the DF CNN (Tensorflow)\n","X_train = X_train[:, :, np.newaxis]\n","X_valid = X_valid[:, :, np.newaxis]\n","X_test = X_test[:, :, np.newaxis]\n","\n","print(X_train.shape[0], 'train samples')\n","print(X_valid.shape[0], 'validation samples')\n","print(X_test.shape[0], 'test samples')\n","\n","# Convert class vectors to categorical classes matrices\n","y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n","y_valid = np_utils.to_categorical(y_valid, NB_CLASSES)\n","y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n","\n","# Building and training model\n","print(\"Building and training DF model\")\n","\n","model = DFNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n","\n","model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n","              metrics=[\"accuracy\"])\n","print(\"Model compiled\")\n","\n","# Start training\n","history = model.fit(X_train, y_train,\n","                    batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n","                    verbose=VERBOSE, validation_data=(X_valid, y_valid))\n","\n","# Start evaluating model with testing data\n","score_test = model.evaluate(X_test, y_test, verbose=VERBOSE)\n","print(\"Testing accuracy:\", score_test[1])\n","\n","# Top N prediction\n","top_N = 2 # Specify top_N = n; n is top-n prediction\n","print(\"Start evaluating Top-%s Accuracy\", %top_N)\n","result = model.predict(X_test, verbose=2) # result는 모델의 예측 확률을 나타내는 리스트. 각 항목은 하나의 샘플에 대한 softmax 확률 벡터.\n","count=0\n","total=0\n","actual_y=y_test\n","for i in range(len(result)):\n","  prob_vec = sorted(result[i]) # 각 샘플의 softmax 확률 벡터 오름차순 정렬.\n","  highest_probs = prob_vec[-top_N:] # pick top_N(two) highest probabilities in softmax\n","  top_list=[] # 상위 확률에 해당하는 클래스 인덱스를 저장할 리스트.\n","  for prob in highest_probs:\n","    top_list.append(list(result[i]).index(prob))\n","  actual_label = list(actual_y[i]).index(1) # convert from one-hot-vector back to actual label. 원-핫 벡터에서 실제 레이블에 해당하는 인덱스(값이 1인 위치)를 반환.\n","  if actual_label in top_list:\n","    count = count + 1\n","  total = total + 1\n","\n","print(\"Top-%s Accuracy: %f \", %(top_N, float(count)/total)"],"metadata":{"id":"mczD0QJ9Irye"},"execution_count":null,"outputs":[]}]}